{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52558b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\n",
      "D:\\handwritten\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('D:/handwritten')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54d8fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels： (60261,)\n",
      "features_pca： (60261, 26)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "features_pca = np.load('top100_features_Proportional_80_pca.npy')\n",
    "labels = np.load('top100_Labels_Proportional.npy')\n",
    "print(\"labels：\", labels.shape)\n",
    "print(\"features_pca：\", features_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e2f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert the string category label to an integer\n",
    "y_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Assign the PCA-processed features to X\n",
    "X = features_pca\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ee4b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56        45\n",
      "           1       0.54      0.34      0.42       312\n",
      "           2       0.00      0.00      0.00       165\n",
      "           3       0.64      0.24      0.35        29\n",
      "           4       0.59      0.46      0.52        35\n",
      "           5       0.20      0.02      0.04        42\n",
      "           6       0.64      0.88      0.74      1113\n",
      "           7       0.70      0.85      0.76        65\n",
      "           8       0.84      0.86      0.85       964\n",
      "           9       0.77      0.66      0.71        35\n",
      "          10       0.74      0.57      0.65        40\n",
      "          11       0.88      0.42      0.57        55\n",
      "          12       1.00      0.04      0.07        56\n",
      "          13       0.00      0.00      0.00        38\n",
      "          14       0.00      0.00      0.00        26\n",
      "          15       0.00      0.00      0.00        45\n",
      "          16       0.00      0.00      0.00        71\n",
      "          17       0.71      0.03      0.06       147\n",
      "          18       0.00      0.00      0.00        36\n",
      "          19       0.00      0.00      0.00        39\n",
      "          20       0.36      0.23      0.28        62\n",
      "          21       0.59      0.24      0.35       119\n",
      "          22       0.00      0.00      0.00        19\n",
      "          23       0.56      0.65      0.60       446\n",
      "          24       0.47      0.45      0.46        31\n",
      "          25       0.17      0.15      0.16        41\n",
      "          26       0.25      0.19      0.21        80\n",
      "          27       0.58      0.85      0.69       518\n",
      "          28       0.32      0.47      0.38        66\n",
      "          29       0.58      0.61      0.60       155\n",
      "          30       0.27      0.21      0.24       108\n",
      "          31       0.33      0.08      0.13       155\n",
      "          32       0.35      0.32      0.34        69\n",
      "          33       0.56      0.58      0.57        33\n",
      "          34       0.36      0.21      0.27        85\n",
      "          35       0.51      0.48      0.49       103\n",
      "          36       0.35      0.26      0.30        31\n",
      "          37       0.50      0.31      0.38        29\n",
      "          38       0.00      0.00      0.00        26\n",
      "          39       0.56      0.15      0.23        34\n",
      "          40       0.38      0.40      0.39       164\n",
      "          41       0.63      0.16      0.26        73\n",
      "          42       0.51      0.31      0.38       162\n",
      "          43       0.27      0.11      0.16        62\n",
      "          44       0.37      0.33      0.35        90\n",
      "          45       0.28      0.09      0.14       182\n",
      "          46       0.30      0.13      0.18        82\n",
      "          47       0.35      0.17      0.23        46\n",
      "          48       0.29      0.24      0.26       140\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.40      0.54      0.46       352\n",
      "          51       0.21      0.10      0.14        29\n",
      "          52       0.55      0.35      0.43       197\n",
      "          53       0.50      0.41      0.45       162\n",
      "          54       0.00      0.00      0.00        29\n",
      "          55       0.50      0.13      0.21        23\n",
      "          56       0.33      0.35      0.34        17\n",
      "          57       0.61      0.69      0.65        29\n",
      "          58       0.00      0.00      0.00        30\n",
      "          59       0.34      0.26      0.30        46\n",
      "          60       0.33      0.06      0.10        18\n",
      "          61       0.31      0.43      0.36        21\n",
      "          62       0.50      0.33      0.40        30\n",
      "          63       0.40      0.04      0.07        52\n",
      "          64       0.58      0.52      0.55        92\n",
      "          65       0.54      0.76      0.63       653\n",
      "          66       0.45      0.50      0.47       148\n",
      "          67       0.26      0.13      0.18        45\n",
      "          68       0.44      0.29      0.35        28\n",
      "          69       0.55      0.40      0.46        45\n",
      "          70       0.60      0.38      0.46        24\n",
      "          71       0.00      0.00      0.00        42\n",
      "          72       0.44      0.30      0.36        23\n",
      "          73       0.38      0.06      0.10        50\n",
      "          74       1.00      0.02      0.04        52\n",
      "          75       0.33      0.02      0.04        43\n",
      "          76       0.21      0.20      0.20        25\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.47      0.54      0.50       249\n",
      "          79       0.46      0.83      0.59      1195\n",
      "          80       0.25      0.12      0.16        50\n",
      "          81       0.20      0.04      0.06        28\n",
      "          82       0.60      0.09      0.15        35\n",
      "          83       0.47      0.53      0.50        51\n",
      "          84       0.33      0.02      0.03        64\n",
      "          85       0.00      0.00      0.00        31\n",
      "          86       0.42      0.51      0.46       518\n",
      "          87       0.00      0.00      0.00        29\n",
      "          88       0.64      0.41      0.50        34\n",
      "          89       0.49      0.69      0.57       217\n",
      "          90       0.27      0.14      0.18        50\n",
      "          91       0.27      0.31      0.29        55\n",
      "          92       0.50      0.21      0.30        33\n",
      "          93       0.56      0.31      0.40        29\n",
      "          94       0.45      0.58      0.51        86\n",
      "          95       0.36      0.10      0.15        51\n",
      "          96       0.42      0.16      0.24        49\n",
      "          97       0.56      0.67      0.61       142\n",
      "          98       0.39      0.30      0.34        53\n",
      "          99       0.78      0.77      0.77        64\n",
      "\n",
      "    accuracy                           0.53     12053\n",
      "   macro avg       0.39      0.29      0.30     12053\n",
      "weighted avg       0.49      0.53      0.48     12053\n",
      "\n",
      "SVM Accuracy: 0.5276694598855057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='linear')  # Choose rbf kernel maybe better\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b59144e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['80_svm_model.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(svm, '80_svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 保存模型\n",
    "with open('80_svm_model.pickle', 'wb') as f:\n",
    "    pickle.dump(svm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39501a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model accuracy: 0.4415498216211732\n"
     ]
    }
   ],
   "source": [
    "# 从文件加载模型\n",
    "svm_loaded = load('svm_model.joblib')\n",
    "\n",
    "# 使用加载的模型进行预测\n",
    "predictions = svm_loaded.predict(X_test)\n",
    "print(\"Loaded model accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072c57e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4415498216211732\n",
      "Precision (Macro-average): 0.22303808565555389\n",
      "Recall (Macro-average): 0.17236039904407308\n",
      "F1 Score (Macro-average): 0.1690514464842048\n",
      "F1 Score (Micro-average): 0.4415498216211732\n",
      "F1 Score (Weighted-average): 0.3678832702346053\n",
      "Confusion Matrix:\n",
      " [[14  0  1 ...  0  0  0]\n",
      " [ 0 79  1 ...  0  0  0]\n",
      " [ 0  7  2 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 87  0  0]\n",
      " [ 0  0  0 ...  1  1  0]\n",
      " [ 0  0  0 ...  0  0 40]]\n",
      "Matthews Correlation Coefficient: 0.41282627666875055\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.31      0.39        45\n",
      "           1       0.49      0.25      0.33       312\n",
      "           2       0.17      0.01      0.02       165\n",
      "           3       0.67      0.07      0.12        29\n",
      "           4       0.40      0.23      0.29        35\n",
      "           5       0.00      0.00      0.00        42\n",
      "           6       0.62      0.88      0.73      1113\n",
      "           7       0.56      0.80      0.66        65\n",
      "           8       0.79      0.84      0.82       964\n",
      "           9       0.79      0.54      0.64        35\n",
      "          10       0.91      0.53      0.67        40\n",
      "          11       0.00      0.00      0.00        55\n",
      "          12       0.00      0.00      0.00        56\n",
      "          13       0.00      0.00      0.00        38\n",
      "          14       0.00      0.00      0.00        26\n",
      "          15       0.00      0.00      0.00        45\n",
      "          16       0.00      0.00      0.00        71\n",
      "          17       0.00      0.00      0.00       147\n",
      "          18       0.00      0.00      0.00        36\n",
      "          19       0.00      0.00      0.00        39\n",
      "          20       0.33      0.02      0.03        62\n",
      "          21       0.18      0.02      0.03       119\n",
      "          22       0.00      0.00      0.00        19\n",
      "          23       0.51      0.53      0.52       446\n",
      "          24       0.40      0.13      0.20        31\n",
      "          25       0.18      0.10      0.13        41\n",
      "          26       0.25      0.07      0.12        80\n",
      "          27       0.35      0.78      0.48       518\n",
      "          28       0.31      0.39      0.35        66\n",
      "          29       0.50      0.41      0.45       155\n",
      "          30       0.31      0.14      0.19       108\n",
      "          31       0.00      0.00      0.00       155\n",
      "          32       0.18      0.12      0.14        69\n",
      "          33       0.48      0.61      0.53        33\n",
      "          34       0.00      0.00      0.00        85\n",
      "          35       0.53      0.36      0.43       103\n",
      "          36       0.25      0.03      0.06        31\n",
      "          37       0.00      0.00      0.00        29\n",
      "          38       0.00      0.00      0.00        26\n",
      "          39       1.00      0.03      0.06        34\n",
      "          40       0.41      0.20      0.27       164\n",
      "          41       0.25      0.04      0.07        73\n",
      "          42       0.18      0.01      0.02       162\n",
      "          43       0.00      0.00      0.00        62\n",
      "          44       0.23      0.18      0.20        90\n",
      "          45       0.17      0.02      0.04       182\n",
      "          46       0.00      0.00      0.00        82\n",
      "          47       0.10      0.02      0.04        46\n",
      "          48       0.00      0.00      0.00       140\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.32      0.56      0.41       352\n",
      "          51       0.00      0.00      0.00        29\n",
      "          52       0.32      0.14      0.20       197\n",
      "          53       0.47      0.23      0.31       162\n",
      "          54       0.00      0.00      0.00        29\n",
      "          55       0.00      0.00      0.00        23\n",
      "          56       0.00      0.00      0.00        17\n",
      "          57       0.44      0.55      0.49        29\n",
      "          58       0.00      0.00      0.00        30\n",
      "          59       0.19      0.07      0.10        46\n",
      "          60       0.00      0.00      0.00        18\n",
      "          61       0.29      0.38      0.33        21\n",
      "          62       0.31      0.17      0.22        30\n",
      "          63       0.00      0.00      0.00        52\n",
      "          64       0.29      0.08      0.12        92\n",
      "          65       0.44      0.75      0.56       653\n",
      "          66       0.39      0.41      0.40       148\n",
      "          67       0.33      0.09      0.14        45\n",
      "          68       0.08      0.04      0.05        28\n",
      "          69       0.38      0.22      0.28        45\n",
      "          70       0.00      0.00      0.00        24\n",
      "          71       0.00      0.00      0.00        42\n",
      "          72       0.00      0.00      0.00        23\n",
      "          73       0.00      0.00      0.00        50\n",
      "          74       0.00      0.00      0.00        52\n",
      "          75       0.00      0.00      0.00        43\n",
      "          76       0.18      0.08      0.11        25\n",
      "          77       0.00      0.00      0.00        36\n",
      "          78       0.22      0.04      0.07       249\n",
      "          79       0.36      0.82      0.50      1195\n",
      "          80       0.00      0.00      0.00        50\n",
      "          81       0.00      0.00      0.00        28\n",
      "          82       0.00      0.00      0.00        35\n",
      "          83       0.36      0.41      0.39        51\n",
      "          84       0.00      0.00      0.00        64\n",
      "          85       0.00      0.00      0.00        31\n",
      "          86       0.35      0.45      0.39       518\n",
      "          87       0.00      0.00      0.00        29\n",
      "          88       0.43      0.35      0.39        34\n",
      "          89       0.31      0.67      0.43       217\n",
      "          90       0.17      0.08      0.11        50\n",
      "          91       0.17      0.29      0.22        55\n",
      "          92       0.00      0.00      0.00        33\n",
      "          93       0.22      0.07      0.11        29\n",
      "          94       0.24      0.23      0.24        86\n",
      "          95       0.00      0.00      0.00        51\n",
      "          96       0.46      0.12      0.19        49\n",
      "          97       0.41      0.61      0.49       142\n",
      "          98       0.50      0.02      0.04        53\n",
      "          99       0.59      0.62      0.61        64\n",
      "\n",
      "    accuracy                           0.44     12053\n",
      "   macro avg       0.22      0.17      0.17     12053\n",
      "weighted avg       0.36      0.44      0.37     12053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "# 预测75\n",
    "svm_predictions = svm.predict(X_test)\n",
    "\n",
    "# 计算基础评估指标\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"Precision (Macro-average):\", precision_score(y_test, svm_predictions, average='macro'))\n",
    "print(\"Recall (Macro-average):\", recall_score(y_test, svm_predictions, average='macro'))\n",
    "print(\"F1 Score (Macro-average):\", f1_score(y_test, svm_predictions, average='macro'))\n",
    "print(\"F1 Score (Micro-average):\", f1_score(y_test, svm_predictions, average='micro'))\n",
    "print(\"F1 Score (Weighted-average):\", f1_score(y_test, svm_predictions, average='weighted'))\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Matthews 相关系数\n",
    "mcc = matthews_corrcoef(y_test, svm_predictions)\n",
    "print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "\n",
    "# 详细分类报告\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fc9217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6287231394673525\n",
      "Precision (Macro-average): 0.4992921979138359\n",
      "Recall (Macro-average): 0.4396726353712934\n",
      "F1 Score (Macro-average): 0.45757556933734267\n",
      "F1 Score (Micro-average): 0.6287231394673525\n",
      "F1 Score (Weighted-average): 0.6100694896627278\n",
      "Confusion Matrix:\n",
      " [[ 31   0   0 ...   0   0   0]\n",
      " [  1 163   3 ...   0   0   0]\n",
      " [  0  10   3 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  88   1   0]\n",
      " [  0   0   0 ...   0  22   0]\n",
      " [  0   2   0 ...   0   0  41]]\n",
      "Matthews Correlation Coefficient: 0.6121363909132537\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           !       0.65      0.69      0.67        45\n",
      "           \"       0.58      0.52      0.55       312\n",
      "           '       0.17      0.02      0.03       165\n",
      "          's       0.53      0.34      0.42        29\n",
      "           (       0.44      0.46      0.45        35\n",
      "           )       0.53      0.19      0.28        42\n",
      "           ,       0.68      0.89      0.77      1113\n",
      "           -       0.72      0.86      0.78        65\n",
      "           .       0.88      0.84      0.86       964\n",
      "         ...       0.70      0.74      0.72        35\n",
      "           :       0.72      0.53      0.61        40\n",
      "           ;       0.86      0.58      0.70        55\n",
      "           ?       0.82      0.57      0.67        56\n",
      "           A       0.33      0.13      0.19        38\n",
      "         And       0.22      0.19      0.20        26\n",
      "         But       0.59      0.38      0.46        45\n",
      "          He       0.31      0.07      0.11        71\n",
      "           I       0.65      0.25      0.36       147\n",
      "          In       0.22      0.17      0.19        36\n",
      "          It       0.32      0.31      0.32        39\n",
      "         Mr.       0.51      0.31      0.38        62\n",
      "         The       0.68      0.53      0.59       119\n",
      "        This       0.29      0.26      0.28        19\n",
      "           a       0.69      0.78      0.74       446\n",
      "       about       0.55      0.68      0.61        31\n",
      "         all       0.43      0.29      0.35        41\n",
      "          an       0.43      0.50      0.46        80\n",
      "         and       0.73      0.88      0.80       518\n",
      "         are       0.45      0.56      0.50        66\n",
      "          as       0.69      0.63      0.66       155\n",
      "          at       0.51      0.49      0.50       108\n",
      "          be       0.43      0.37      0.40       155\n",
      "        been       0.44      0.45      0.44        69\n",
      "       being       0.50      0.70      0.58        33\n",
      "         but       0.53      0.49      0.51        85\n",
      "          by       0.62      0.56      0.59       103\n",
      "         can       0.49      0.55      0.52        31\n",
      "       could       0.38      0.52      0.44        29\n",
      "          do       0.41      0.35      0.38        26\n",
      "       first       0.39      0.41      0.40        34\n",
      "         for       0.59      0.65      0.62       164\n",
      "        from       0.50      0.42      0.46        73\n",
      "         had       0.63      0.45      0.53       162\n",
      "         has       0.37      0.39      0.38        62\n",
      "        have       0.51      0.44      0.47        90\n",
      "          he       0.53      0.37      0.44       182\n",
      "         her       0.44      0.40      0.42        82\n",
      "         him       0.35      0.30      0.33        46\n",
      "         his       0.55      0.43      0.48       140\n",
      "          if       0.00      0.00      0.00        30\n",
      "          in       0.54      0.63      0.58       352\n",
      "        into       0.19      0.17      0.18        29\n",
      "          is       0.63      0.52      0.57       197\n",
      "          it       0.52      0.48      0.50       162\n",
      "        like       0.30      0.10      0.15        29\n",
      "        made       0.44      0.35      0.39        23\n",
      "         man       0.43      0.53      0.47        17\n",
      "         may       0.47      0.52      0.49        29\n",
      "          me       0.21      0.10      0.14        30\n",
      "        more       0.45      0.41      0.43        46\n",
      "        much       0.23      0.17      0.19        18\n",
      "          my       0.43      0.57      0.49        21\n",
      "         new       0.50      0.33      0.40        30\n",
      "          no       0.56      0.37      0.44        52\n",
      "         not       0.53      0.60      0.56        92\n",
      "          of       0.77      0.84      0.80       653\n",
      "          on       0.66      0.56      0.61       148\n",
      "         one       0.57      0.38      0.45        45\n",
      "        only       0.55      0.39      0.46        28\n",
      "          or       0.53      0.51      0.52        45\n",
      "       other       0.57      0.33      0.42        24\n",
      "         out       0.27      0.14      0.19        42\n",
      "        over       0.48      0.43      0.45        23\n",
      "        said       0.55      0.44      0.49        50\n",
      "         she       0.38      0.06      0.10        52\n",
      "          so       0.38      0.33      0.35        43\n",
      "        some       0.50      0.48      0.49        25\n",
      "        than       0.24      0.17      0.20        36\n",
      "        that       0.66      0.71      0.68       249\n",
      "         the       0.63      0.85      0.72      1195\n",
      "       their       0.38      0.26      0.31        50\n",
      "        them       0.45      0.36      0.40        28\n",
      "       there       0.39      0.31      0.35        35\n",
      "        they       0.58      0.55      0.57        51\n",
      "        this       0.45      0.23      0.31        64\n",
      "        time       0.17      0.06      0.09        31\n",
      "          to       0.56      0.67      0.61       518\n",
      "         two       0.47      0.31      0.38        29\n",
      "          up       0.77      0.71      0.74        34\n",
      "         was       0.70      0.72      0.71       217\n",
      "          we       0.44      0.36      0.40        50\n",
      "        were       0.35      0.35      0.35        55\n",
      "        what       0.50      0.45      0.48        33\n",
      "        when       0.26      0.31      0.29        29\n",
      "       which       0.67      0.52      0.59        86\n",
      "         who       0.49      0.33      0.40        51\n",
      "        will       0.44      0.41      0.43        49\n",
      "        with       0.75      0.62      0.68       142\n",
      "       would       0.63      0.42      0.50        53\n",
      "         you       0.73      0.64      0.68        64\n",
      "\n",
      "    accuracy                           0.63     12053\n",
      "   macro avg       0.50      0.44      0.46     12053\n",
      "weighted avg       0.61      0.63      0.61     12053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "# 预测90\n",
    "svm_predictions = svm.predict(X_test)\n",
    "\n",
    "# 将预测结果和实际标签转换回原始字符串标签\n",
    "svm_predictions_labels = label_encoder.inverse_transform(svm_predictions)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# 计算基础评估指标\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"Precision (Macro-average):\", precision_score(y_test, svm_predictions, average='macro'))\n",
    "print(\"Recall (Macro-average):\", recall_score(y_test, svm_predictions, average='macro'))\n",
    "print(\"F1 Score (Macro-average):\", f1_score(y_test, svm_predictions, average='macro'))\n",
    "print(\"F1 Score (Micro-average):\", f1_score(y_test, svm_predictions, average='micro'))\n",
    "print(\"F1 Score (Weighted-average):\", f1_score(y_test, svm_predictions, average='weighted'))\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test_labels, svm_predictions_labels)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Matthews 相关系数\n",
    "mcc = matthews_corrcoef(y_test, svm_predictions)\n",
    "print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "\n",
    "# 详细分类报告\n",
    "print(\"Detailed classification report:\\n\")\n",
    "print(classification_report(y_test_labels, svm_predictions_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b7aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要，将预测的整数标签转回原始字符串\n",
    "y_pred_labels = label_encoder.inverse_transform(predictions.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adfcd2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to' ',' 'the' ... 'and' ',' 'in']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
